{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Chunks - Word2Vec (LSTM, CNN)"
      ],
      "metadata": {
        "id": "xivbitchJNId"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports & Installs"
      ],
      "metadata": {
        "id": "9VE30eioJM-N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E1BbdCYoIaN8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5db32127-8976-49bc-a46b-46a7ee2f59b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorstore 0.1.68 requires ml-dtypes>=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.15.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# !pip install tf-keras --quiet\n",
        "# !pip install gensim --quiet\n",
        "# !pip install tensorflow-text --quiet\n",
        "\n",
        "!pip install gensim --quiet\n",
        "!pip install tensorflow==2.15.0 --quiet\n",
        "!pip install tf_keras==2.15.0 --quiet\n",
        "!pip install tensorflow-text==2.15.0 --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import libraries\n",
        "import pandas as pd\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "from keras.layers import Embedding, Input, Dense, Lambda\n",
        "from keras.models import Model\n",
        "#import keras.backend as K\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_text as tf_text\n",
        "\n",
        "import sklearn as sk\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import nltk\n",
        "from nltk.data import find\n",
        "from nltk.tokenize import sent_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import re\n",
        "\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors\n",
        "from gensim.test.utils import datapath\n",
        "\n",
        "# import altair as alt\n",
        "# from altair_data_server import data_server"
      ],
      "metadata": {
        "id": "3aME7fqNI8Pl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7e96396-2763-4109-995d-b5237771738a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4-window plot of loss and accuracy for two models, for comparison\n",
        "\n",
        "def make_plot(axs,\n",
        "              model_history1,\n",
        "              model_history2,\n",
        "              model_1_name='model 1',\n",
        "              model_2_name='model 2',\n",
        "              ):\n",
        "    box = dict(facecolor='yellow', pad=5, alpha=0.2)\n",
        "\n",
        "    for i, metric in enumerate(['loss', 'accuracy']):\n",
        "        y_lim_lower1 = np.min(model_history1.history[metric])\n",
        "        y_lim_lower2 = np.min(model_history2.history[metric])\n",
        "        y_lim_lower = min(y_lim_lower1, y_lim_lower2) * 0.9\n",
        "\n",
        "        y_lim_upper1 = np.max(model_history1.history[metric])\n",
        "        y_lim_upper2 = np.max(model_history2.history[metric])\n",
        "        y_lim_upper = max(y_lim_upper1, y_lim_upper2) * 1.1\n",
        "\n",
        "        for j, model_history in enumerate([model_history1, model_history2]):\n",
        "            model_name = [model_1_name, model_2_name][j]\n",
        "            ax1 = axs[i, j]\n",
        "            ax1.plot(model_history.history[metric])\n",
        "            ax1.plot(model_history.history['val_%s' % metric])\n",
        "            ax1.set_title('%s - %s' % (metric, model_name))\n",
        "            ax1.set_ylabel(metric, bbox=box)\n",
        "            ax1.set_ylim(y_lim_lower, y_lim_upper)"
      ],
      "metadata": {
        "id": "TZ9TdpGjJBnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read and Prepare Data"
      ],
      "metadata": {
        "id": "XmRULDS9JIfN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount drive and read input files\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "final_data_folder = '/content/drive/MyDrive/266 Final Project/Full Orchestration: Stage 1+2/final_data/'\n",
        "training_data = pd.read_csv(final_data_folder + 'chunk_training_data.csv')\n",
        "testing_data = pd.read_csv(final_data_folder + 'chunk_testing_data.csv')\n",
        "\n",
        "training_data.head()\n",
        "# chunk_highlights = pd.read_csv('/content/drive/MyDrive/266 Final Project/Processed Data/chunk_highlights.csv')\n",
        "# chunk_highlights['highlight'] = chunk_highlights['highlight'].fillna('')\n",
        "# chunk_highlights['label'] = chunk_highlights['highlight'].apply(lambda x: 0 if x =='' else 1)\n",
        "# chunk_highlights.head()"
      ],
      "metadata": {
        "id": "8F4xvhugJL92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "2654df49-5666-43e8-bbb7-f5272dcaadab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   service_id service_name                                  doc_type  \\\n",
              "0        1588     Coinbase  CB Payments & COINBASE UK PRIVACY POLICY   \n",
              "1         831     Clockify                              Terms of Use   \n",
              "2        1593       ISODME                            Privacy Policy   \n",
              "3         185      Netflix                              Terms of Use   \n",
              "4         836      Scratch        Privacy Policy (February 14, 2019)   \n",
              "\n",
              "                                            doc_text  \\\n",
              "0  With law enforcement, officials, or other thir...   \n",
              "1  AGREEMENT AMENDMENTS COING may revise and upda...   \n",
              "2  Tracking technologies and Cookies. We use cook...   \n",
              "3  The member who created the Netflix account and...   \n",
              "4  Parents and guardians who register their under...   \n",
              "\n",
              "                                           highlight  \\\n",
              "0  With law enforcement, officials, or other thir...   \n",
              "1  Any changes shall enter into force upon being ...   \n",
              "2  We use cookies, beacons, tags, scripts and oth...   \n",
              "3  You are responsible for updating and maintaini...   \n",
              "4  The results of this research are shared with e...   \n",
              "\n",
              "                                          paraphrase  label  \n",
              "0  This service reserves the right to disclose yo...      1  \n",
              "1  When the service wants to change its terms, us...      1  \n",
              "2  The service may use tracking pixels, web beaco...      1  \n",
              "3  You must provide your legal name, pseudonyms a...      1  \n",
              "4   Your personal data is aggregated into statistics      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-39fd2ff3-c1c2-4a91-b3b8-748b02c49f80\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>service_id</th>\n",
              "      <th>service_name</th>\n",
              "      <th>doc_type</th>\n",
              "      <th>doc_text</th>\n",
              "      <th>highlight</th>\n",
              "      <th>paraphrase</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1588</td>\n",
              "      <td>Coinbase</td>\n",
              "      <td>CB Payments &amp; COINBASE UK PRIVACY POLICY</td>\n",
              "      <td>With law enforcement, officials, or other thir...</td>\n",
              "      <td>With law enforcement, officials, or other thir...</td>\n",
              "      <td>This service reserves the right to disclose yo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>831</td>\n",
              "      <td>Clockify</td>\n",
              "      <td>Terms of Use</td>\n",
              "      <td>AGREEMENT AMENDMENTS COING may revise and upda...</td>\n",
              "      <td>Any changes shall enter into force upon being ...</td>\n",
              "      <td>When the service wants to change its terms, us...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1593</td>\n",
              "      <td>ISODME</td>\n",
              "      <td>Privacy Policy</td>\n",
              "      <td>Tracking technologies and Cookies. We use cook...</td>\n",
              "      <td>We use cookies, beacons, tags, scripts and oth...</td>\n",
              "      <td>The service may use tracking pixels, web beaco...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>185</td>\n",
              "      <td>Netflix</td>\n",
              "      <td>Terms of Use</td>\n",
              "      <td>The member who created the Netflix account and...</td>\n",
              "      <td>You are responsible for updating and maintaini...</td>\n",
              "      <td>You must provide your legal name, pseudonyms a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>836</td>\n",
              "      <td>Scratch</td>\n",
              "      <td>Privacy Policy (February 14, 2019)</td>\n",
              "      <td>Parents and guardians who register their under...</td>\n",
              "      <td>The results of this research are shared with e...</td>\n",
              "      <td>Your personal data is aggregated into statistics</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-39fd2ff3-c1c2-4a91-b3b8-748b02c49f80')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-39fd2ff3-c1c2-4a91-b3b8-748b02c49f80 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-39fd2ff3-c1c2-4a91-b3b8-748b02c49f80');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e8624165-cd9a-406d-8f7f-837da83d8bcc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e8624165-cd9a-406d-8f7f-837da83d8bcc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e8624165-cd9a-406d-8f7f-837da83d8bcc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"# chunk_highlights\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"service_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 595,\n        \"min\": 185,\n        \"max\": 1593,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          831,\n          836,\n          1593\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"service_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Clockify\",\n          \"Scratch\",\n          \"ISODME\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"doc_type\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Terms of Use\",\n          \"Privacy Policy (February 14, 2019)\",\n          \"CB Payments & COINBASE UK PRIVACY POLICY\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"doc_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"AGREEMENT AMENDMENTS COING may revise and update these Terms of Use or any part of Agreement at any time. If you use Cloud Clockify, you are cautioned to review the Terms of Use posted on the Website periodically. Any changes shall enter into force upon being published on the Website andor after at least 10 days after you have received a notification from us via email.\",\n          \"Parents and guardians who register their under16 year olds for Scratch may also receive additional updates from the Scratch Foundation, a nonprofit that supports Scratch educational initiatives. Aggregate Data\\nWe may deidentify and aggregate information collected through the Site for statistical analysis and other lawful purpose, including in research studies intended to improve our understanding of how people learn with Scratch. The results of this research are shared with educators and researchers through conferences, journals, and other publications.\",\n          \"Tracking technologies and Cookies. We use cookies, beacons, tags, scripts and other similar technologies, such as CI codes click tracking, ISC source tracking, and ITC item tracking codes. We also automatically collect information about devices operating system, phone model, device ID and customer number.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"highlight\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Any changes shall enter into force upon being published on the Website andor after at least 10 days after you have received a notification from us via email.\",\n          \"The results of this research are shared with educators and researchers through conferences, journals, and other publications.\",\n          \"We use cookies, beacons, tags, scripts and other similar technologies, such as CI codes click tracking, ISC source tracking, and ITC item tracking codes.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"paraphrase\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"When the service wants to change its terms, users are notified a week or more in advance.\",\n          \"Your personal data is aggregated into statistics\",\n          \"The service may use tracking pixels, web beacons, browser fingerprinting, and/or device fingerprinting on users.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# class1_df = chunk_highlights[chunk_highlights['label'] == 1]\n",
        "# class0_df = chunk_highlights[chunk_highlights['label'] == 0].sample(n = len(chunk_highlights[chunk_highlights['label'] == 1]))\n",
        "# balanced_df = pd.concat([class1_df, class0_df])\n",
        "# balanced_df['label'].value_counts()"
      ],
      "metadata": {
        "id": "VDG1FGbTMPE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X = balanced_df['doc_text'].values\n",
        "# y = balanced_df['label'].values\n",
        "# # y = balanced_df['highlight'].values\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 1)\n",
        "# print(X_train.shape)\n",
        "# print(X_test.shape)"
      ],
      "metadata": {
        "id": "UCCmRCgOOKHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM Experiment"
      ],
      "metadata": {
        "id": "g9Z93XBdPkfk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize train and test data\n",
        "tokenizer = tf_text.WhitespaceTokenizer()\n",
        "train_tokens = tokenizer.tokenize(training_data['doc_text'].values)\n",
        "test_tokens = tokenizer.tokenize(testing_data['doc_text'].values)\n",
        "\n",
        "# Take a look at a training example\n",
        "train_tokens[0]"
      ],
      "metadata": {
        "id": "2LAfrBF2PlZD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fea542b0-09e9-4ddd-d8d8-30e788759381"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(153,), dtype=string, numpy=\n",
              "array([b'With', b'law', b'enforcement,', b'officials,', b'or', b'other',\n",
              "       b'third', b'parties', b'when', b'we', b'are', b'compelled', b'to',\n",
              "       b'do', b'so', b'by', b'a', b'subpoena,', b'court', b'order,',\n",
              "       b'or', b'similar', b'legal', b'procedure,', b'or', b'when', b'we',\n",
              "       b'believe', b'in', b'good', b'faith', b'that', b'the',\n",
              "       b'disclosure', b'of', b'personal', b'information', b'is',\n",
              "       b'necessary', b'to', b'prevent', b'physical', b'harm', b'or',\n",
              "       b'financial', b'loss,', b'to', b'report', b'suspected', b'illegal',\n",
              "       b'activity,', b'or', b'to', b'investigate', b'violations', b'of',\n",
              "       b'our', b'User', b'Agreement', b'or', b'any', b'other',\n",
              "       b'applicable', b'policies.', b'If', b'you', b'establish', b'a',\n",
              "       b'CB', b'Account', b'indirectly', b'on', b'a', b'third', b'party',\n",
              "       b'website', b'or', b'via', b'a', b'third', b'party',\n",
              "       b'application,', b'any', b'information', b'that', b'you', b'enter',\n",
              "       b'on', b'that', b'website', b'or', b'application', b'and', b'not',\n",
              "       b'directly', b'on', b'a', b'CB', b'website', b'will', b'be',\n",
              "       b'shared', b'with', b'the', b'owner', b'of', b'the', b'third',\n",
              "       b'party', b'website', b'or', b'application', b'and', b'your',\n",
              "       b'information', b'will', b'be', b'subject', b'to', b'their',\n",
              "       b'privacy', b'policies.', b'THIRDPARTY', b'SITES', b'AND',\n",
              "       b'SERVICES', b'If', b'you', b'authorize', b'one', b'or', b'more',\n",
              "       b'thirdparty', b'applications', b'to', b'access', b'your', b'CB',\n",
              "       b'Services,', b'then', b'information', b'you', b'have',\n",
              "       b'provided', b'to', b'CB', b'may', b'be', b'shared', b'with',\n",
              "       b'those', b'third', b'parties.'], dtype=object)>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('word2vec_sample')\n",
        "\n",
        "word2vec_sample = str(find('models/word2vec_sample/pruned.word2vec.txt'))\n",
        "\n",
        "wvmodel = KeyedVectors.load_word2vec_format(datapath(word2vec_sample), binary=False)"
      ],
      "metadata": {
        "id": "se5GRs05P4Xy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d42d02d-9885-4122-de6e-8974a250fec0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package word2vec_sample to /root/nltk_data...\n",
            "[nltk_data]   Unzipping models/word2vec_sample.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 300\n",
        "\n",
        "# initialize embedding matrix and word-to-id map:\n",
        "embedding_matrix = np.zeros((len(wvmodel) + 1, EMBEDDING_DIM))\n",
        "vocab_dict = {}\n",
        "\n",
        "# build the embedding matrix and the word-to-id map:\n",
        "for i, word in enumerate(wvmodel.index_to_key):\n",
        "    embedding_vector = wvmodel[word]\n",
        "\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "        vocab_dict[word] = i\n",
        "\n",
        "# we can use the last index at the end of the vocab for unknown tokens\n",
        "vocab_dict['[UNK]'] = len(vocab_dict)"
      ],
      "metadata": {
        "id": "y-zKN7sRP4RD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_SEQUENCE_LENGTH = 256\n",
        "\n",
        "def docs_to_vocab_ids(tokenized_texts_list, MAX_SEQUENCE_LENGTH):\n",
        "    \"\"\"\n",
        "    converting a list of strings to a list of lists of word ids\n",
        "    \"\"\"\n",
        "    texts_vocab_ids = []\n",
        "    text_labels = []\n",
        "    valid_example_list = []\n",
        "    for i, token_list in enumerate(tokenized_texts_list):\n",
        "\n",
        "        # Get the vocab id for each token in this doc ([UNK] if not in vocab)\n",
        "        vocab_ids = []\n",
        "        for token in list(token_list.numpy()):\n",
        "            decoded = token.decode('utf-8', errors='ignore')\n",
        "            if decoded in vocab_dict:\n",
        "                vocab_ids.append(vocab_dict[decoded])\n",
        "            else:\n",
        "                vocab_ids.append(vocab_dict['[UNK]'])\n",
        "\n",
        "        # Truncate text to max length, add padding up to max length\n",
        "        vocab_ids = vocab_ids[:MAX_SEQUENCE_LENGTH]\n",
        "        n_padding = (MAX_SEQUENCE_LENGTH - len(vocab_ids))\n",
        "        # For simplicity in this model, we'll just pad with unknown tokens\n",
        "        vocab_ids += [vocab_dict['[UNK]']] * n_padding\n",
        "        # Add this example to the list of converted docs\n",
        "        texts_vocab_ids.append(vocab_ids)\n",
        "\n",
        "        if i % 5000 == 0:\n",
        "            print('Examples processed: ', i)\n",
        "\n",
        "    print('Total examples: ', i)\n",
        "    return np.array(texts_vocab_ids)"
      ],
      "metadata": {
        "id": "PjRH-NFOP4Ea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_input = docs_to_vocab_ids(train_tokens, MAX_SEQUENCE_LENGTH)\n",
        "test_input = docs_to_vocab_ids(test_tokens, MAX_SEQUENCE_LENGTH)\n",
        "\n",
        "train_labels = np.array(training_data['label'].values)\n",
        "test_labels = np.array(testing_data['label'].values)"
      ],
      "metadata": {
        "id": "6O55SpR7P393",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60da72e2-f231-42e1-81e1-90534f11be36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Examples processed:  0\n",
            "Examples processed:  5000\n",
            "Total examples:  9567\n",
            "Examples processed:  0\n",
            "Examples processed:  5000\n",
            "Total examples:  5409\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_lstm_model(lstm_units, MAX_SEQUENCE_LENGTH, embeddings_trainable=False):\n",
        "  lstm_input_layer = tf.keras.layers.Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int64')\n",
        "  lstm_embeddings = tf.keras.layers.Embedding(embedding_matrix.shape[0],\n",
        "                                                    embedding_matrix.shape[1],\n",
        "                                                    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
        "                                                    input_length=MAX_SEQUENCE_LENGTH,\n",
        "                                                    trainable=embeddings_trainable)(lstm_input_layer)\n",
        "\n",
        "  lstm_layer = tf.keras.layers.LSTM(units=lstm_units, return_sequences=True, name='lstm_layer')(lstm_embeddings)\n",
        "  # lstm_layer = tf.keras.layers.Dense(10, activation='relu', name='hidden_layer')(lstm_layer)\n",
        "  lstm_layer = tf.keras.layers.Dropout(0.2)(lstm_layer)\n",
        "\n",
        "  lstm_layer = tf.keras.layers.LSTM(units=lstm_units, return_sequences=False, name='lstm_layer')(lstm_embeddings)\n",
        "  lstm_layer = tf.keras.layers.Dropout(0.2)(lstm_layer)\n",
        "\n",
        "  lstm_prediction = tf.keras.layers.Dense(1, activation='sigmoid', name='lstm_output_layer')(lstm_layer)\n",
        "\n",
        "  lstm_model = tf.keras.Model(inputs=lstm_input_layer, outputs=lstm_prediction)\n",
        "  lstm_model.compile(loss='binary_crossentropy',\n",
        "                    optimizer=keras.optimizers.Adam(learning_rate=0.0001,\n",
        "                                                    beta_1=0.9,\n",
        "                                                    beta_2=0.999,\n",
        "                                                    epsilon=1e-07,\n",
        "                                                    amsgrad=False),\n",
        "                    metrics=['accuracy'])\n",
        "\n",
        "  return lstm_model"
      ],
      "metadata": {
        "id": "jFZ6-CJVP33i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "lstm_model = build_lstm_model(lstm_units=16, MAX_SEQUENCE_LENGTH=256)\n",
        "lstm_history =lstm_model.fit(train_input,\n",
        "                             train_labels,\n",
        "                             validation_data=(test_input, test_labels),\n",
        "                             batch_size=16,\n",
        "                             epochs=3\n",
        "                            )"
      ],
      "metadata": {
        "id": "cV9hRLoVQbTE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3b8f8ee-77c8-48f3-dc5b-049d71070365"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "598/598 [==============================] - 55s 89ms/step - loss: 0.6931 - accuracy: 0.4954 - val_loss: 0.6932 - val_accuracy: 0.2262\n",
            "Epoch 2/3\n",
            "598/598 [==============================] - 47s 78ms/step - loss: 0.6927 - accuracy: 0.4943 - val_loss: 0.6926 - val_accuracy: 0.2307\n",
            "Epoch 3/3\n",
            "598/598 [==============================] - 46s 77ms/step - loss: 0.6924 - accuracy: 0.5043 - val_loss: 0.6980 - val_accuracy: 0.2272\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM unit size refers to the dimensionality of the output space for each time step. Each time step will output an n-dimensional vector. This vector represents the learned features from the input sequence up to that point.\n",
        "\n",
        "This hyperparameter controls the \"capacity\" of the LSTM cell to learn and store information over time. A higher number of units increase the capacity to capture complex patterns, but uses more memory and can lead to overfitting. A lower number of units reduces model complexity, which lowers runtime and overfitting, but may miss patterns in the data."
      ],
      "metadata": {
        "id": "msMoMsALQhVS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN Experiment"
      ],
      "metadata": {
        "id": "i2sbprMqRTKC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_cnn_model(num_filters, kernel_sizes, dense_layer_dims, dropout_rate, embeddings_trainable=False):\n",
        "    cnn_input_layer = keras.layers.Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int64')\n",
        "    cnn_embedding_layer = Embedding(embedding_matrix.shape[0],\n",
        "                                    embedding_matrix.shape[1],\n",
        "                                    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
        "                                    input_length=MAX_SEQUENCE_LENGTH,\n",
        "                                    trainable=embeddings_trainable)\n",
        "    cnn_embeddings = cnn_embedding_layer(cnn_input_layer)\n",
        "\n",
        "    conv_layers_for_all_kernel_sizes = []\n",
        "    for kernel_size, filters in zip(kernel_sizes, num_filters):\n",
        "        conv_layer = keras.layers.Conv1D(filters=filters, kernel_size=kernel_size, activation='relu')(cnn_embeddings)\n",
        "        conv_layer = keras.layers.GlobalMaxPooling1D()(conv_layer)\n",
        "        conv_layers_for_all_kernel_sizes.append(conv_layer)\n",
        "\n",
        "    conv_output = keras.layers.concatenate(conv_layers_for_all_kernel_sizes, axis=1)\n",
        "    last_hidden_output = keras.layers.Dropout(rate=dropout_rate)(conv_output)\n",
        "\n",
        "    for dense_layer_dim in dense_layer_dims:\n",
        "        last_hidden_output = keras.layers.Dense(dense_layer_dim, activation='relu')(last_hidden_output)\n",
        "\n",
        "    cnn_prediction = keras.layers.Dense(1, activation='sigmoid')(last_hidden_output)\n",
        "\n",
        "    cnn_model = keras.Model(inputs=cnn_input_layer, outputs=cnn_prediction)\n",
        "    cnn_model.compile(optimizer='adam',\n",
        "                      loss='binary_crossentropy',  # From information theory notebooks.\n",
        "                      metrics=['accuracy'])\n",
        "    return cnn_model"
      ],
      "metadata": {
        "id": "muKIayMVL8ja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now specify model hyperparameters and call the function to create a CNN model\n",
        "\n",
        "num_filters = [100, 100, 50, 25]\n",
        "kernel_sizes = [3, 4, 5, 10]\n",
        "dense_layer_dims = [100, 50]\n",
        "dropout_rate = 0.5\n",
        "\n",
        "cnn_model = build_cnn_model(num_filters, kernel_sizes, dense_layer_dims, dropout_rate)"
      ],
      "metadata": {
        "id": "wEAXiUShL8hC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_history = cnn_model.fit(train_input, train_labels,\n",
        "                            validation_data=(test_input, test_labels),\n",
        "                            batch_size=32,\n",
        "                            epochs=5\n",
        "                            )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iD_wbf5vMDso",
        "outputId": "83dff74d-d76b-4c4b-b364-b7ed281452e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 19ms/step - accuracy: 0.5290 - loss: 0.6895 - val_accuracy: 0.6405 - val_loss: 0.6575\n",
            "Epoch 2/5\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6270 - loss: 0.6439 - val_accuracy: 0.6363 - val_loss: 0.6331\n",
            "Epoch 3/5\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7008 - loss: 0.5749 - val_accuracy: 0.7059 - val_loss: 0.5674\n",
            "Epoch 4/5\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7658 - loss: 0.4946 - val_accuracy: 0.7380 - val_loss: 0.5277\n",
            "Epoch 5/5\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8195 - loss: 0.4057 - val_accuracy: 0.7270 - val_loss: 0.5789\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pKYcBt4haMbS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}